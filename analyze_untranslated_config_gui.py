#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æconfig_gui.pyä¸­æœªç¿»è¯‘çš„ä¸­æ–‡å­—ç¬¦ä¸²
å¯¹æ¯”en_US.jsonç¿»è¯‘æ–‡ä»¶ï¼Œæ‰¾å‡ºç¼ºå¤±çš„ç¿»è¯‘
"""

import re
import json
from pathlib import Path

def extract_chinese_strings_from_file(file_path):
    """ä»æ–‡ä»¶ä¸­æå–æ‰€æœ‰ç¡¬ç¼–ç çš„ä¸­æ–‡å­—ç¬¦ä¸²"""
    chinese_strings = {}

    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    # åŒ¹é…ä¸­æ–‡å­—ç¬¦ä¸²çš„æ­£åˆ™è¡¨è¾¾å¼
    # 1. å•å¼•å·æˆ–åŒå¼•å·åŒ…è£¹çš„çº¯ä¸­æ–‡å­—ç¬¦ä¸²
    # 2. åŒ…å«ä¸­æ–‡çš„f-string
    pattern = r'["\']([^"\']*[\u4e00-\u9fff]+[^"\']*)["\']'

    for line_num, line in enumerate(lines, 1):
        # è·³è¿‡æ³¨é‡Šè¡Œ
        if line.strip().startswith('#'):
            continue

        matches = re.finditer(pattern, line)
        for match in matches:
            chinese_text = match.group(1)
            # è¿‡æ»¤æ‰ä¸€äº›ç‰¹æ®Šæƒ…å†µï¼ˆå¦‚æ–‡ä»¶è·¯å¾„ã€URLç­‰ï¼‰
            if '/' not in chinese_text and '\\' not in chinese_text:
                if chinese_text not in chinese_strings:
                    chinese_strings[chinese_text] = []
                chinese_strings[chinese_text].append(line_num)

    return chinese_strings

def load_translation_keys(json_path):
    """åŠ è½½ç¿»è¯‘æ–‡ä»¶ä¸­çš„æ‰€æœ‰key"""
    with open(json_path, 'r', encoding='utf-8') as f:
        translations = json.load(f)

    def extract_keys(obj, prefix=''):
        """é€’å½’æå–æ‰€æœ‰åµŒå¥—çš„key"""
        keys = []
        if isinstance(obj, dict):
            for k, v in obj.items():
                full_key = f"{prefix}.{k}" if prefix else k
                if isinstance(v, dict):
                    keys.extend(extract_keys(v, full_key))
                else:
                    keys.append((full_key, v))
        return keys

    return extract_keys(translations)

def categorize_strings_by_tab(line_num):
    """æ ¹æ®è¡Œå·åˆ¤æ–­å­—ç¬¦ä¸²å±äºå“ªä¸ªtab"""
    if 1612 <= line_num < 1985:
        return "å¤–è§‚é…ç½®"
    elif 1985 <= line_num < 2517:
        return "ä»»åŠ¡ç®¡ç†"
    elif 2517 <= line_num < 2818:
        return "åœºæ™¯è®¾ç½®"
    elif 2818 <= line_num < 3016:
        return "é€šçŸ¥è®¾ç½®"
    elif 3016 <= line_num < 6835:
        return "ä¸ªäººä¸­å¿ƒ"
    elif 6835 <= line_num < 7500:
        return "å…³äº"
    else:
        return "å…¶ä»–/é€šç”¨"

def main():
    # æ–‡ä»¶è·¯å¾„
    config_gui_path = Path('config_gui.py')
    zh_json_path = Path('i18n/zh_CN.json')
    en_json_path = Path('i18n/en_US.json')

    print("æ­£åœ¨åˆ†æ config_gui.py ä¸­çš„ç¡¬ç¼–ç ä¸­æ–‡å­—ç¬¦ä¸²...")
    chinese_strings = extract_chinese_strings_from_file(config_gui_path)

    print(f"å…±æ‰¾åˆ° {len(chinese_strings)} ä¸ªä¸åŒçš„ä¸­æ–‡å­—ç¬¦ä¸²\n")

    print("æ­£åœ¨åŠ è½½ç¿»è¯‘æ–‡ä»¶...")
    zh_translations = load_translation_keys(zh_json_path)
    en_translations = load_translation_keys(en_json_path)

    # åˆ›å»ºä¸­æ–‡åˆ°ç¿»è¯‘keyçš„æ˜ å°„
    zh_to_key = {v: k for k, v in zh_translations}

    # åˆ†ç±»ç»Ÿè®¡
    categorized_missing = {}
    has_zh_key_but_no_en = []
    completely_missing = []

    for chinese_text, line_numbers in chinese_strings.items():
        # åˆ¤æ–­æ˜¯å¦æœ‰ä¸­æ–‡ç¿»è¯‘key
        if chinese_text in zh_to_key:
            zh_key = zh_to_key[chinese_text]
            # æ£€æŸ¥è‹±æ–‡ç¿»è¯‘æ˜¯å¦å­˜åœ¨ä¸”ä¸æ˜¯ä¸­æ–‡
            en_value = next((v for k, v in en_translations if k == zh_key), None)
            if en_value is None or any('\u4e00' <= c <= '\u9fff' for c in str(en_value)):
                has_zh_key_but_no_en.append({
                    'text': chinese_text,
                    'key': zh_key,
                    'en_value': en_value,
                    'lines': line_numbers
                })
        else:
            # å®Œå…¨ç¼ºå¤±ç¿»è¯‘key
            category = categorize_strings_by_tab(line_numbers[0])
            if category not in categorized_missing:
                categorized_missing[category] = []
            categorized_missing[category].append({
                'text': chinese_text,
                'lines': line_numbers
            })
            completely_missing.append({
                'text': chinese_text,
                'lines': line_numbers,
                'category': category
            })

    # ç”ŸæˆæŠ¥å‘Š
    report = []
    report.append("=" * 80)
    report.append("Config GUI æœªç¿»è¯‘å­—ç¬¦ä¸²åˆ†ææŠ¥å‘Š")
    report.append("=" * 80)
    report.append("")

    report.append(f"ğŸ“Š ç»Ÿè®¡æ‘˜è¦")
    report.append(f"  â€¢ æ€»ä¸­æ–‡å­—ç¬¦ä¸²æ•°: {len(chinese_strings)}")
    report.append(f"  â€¢ å®Œå…¨ç¼ºå¤±ç¿»è¯‘key: {len(completely_missing)}")
    report.append(f"  â€¢ æœ‰ä¸­æ–‡keyä½†è‹±æ–‡ç¿»è¯‘ç¼ºå¤±/é”™è¯¯: {len(has_zh_key_but_no_en)}")
    report.append("")

    # æŒ‰tabåˆ†ç±»æ˜¾ç¤ºå®Œå…¨ç¼ºå¤±çš„ç¿»è¯‘
    if categorized_missing:
        report.append("=" * 80)
        report.append("ğŸ“‹ æŒ‰Tabåˆ†ç±»çš„ç¼ºå¤±ç¿»è¯‘ï¼ˆå®Œå…¨æ²¡æœ‰i18n keyï¼‰")
        report.append("=" * 80)
        report.append("")

        for category, items in sorted(categorized_missing.items()):
            report.append(f"\nã€{category}ã€‘({len(items)} é¡¹)")
            report.append("-" * 60)
            for item in items[:20]:  # æ¯ä¸ªåˆ†ç±»åªæ˜¾ç¤ºå‰20ä¸ª
                lines_str = ', '.join(map(str, item['lines'][:5]))
                if len(item['lines']) > 5:
                    lines_str += f" ... (+{len(item['lines'])-5}å¤„)"
                report.append(f"  è¡Œ {lines_str:20s} | {item['text']}")
            if len(items) > 20:
                report.append(f"  ... è¿˜æœ‰ {len(items)-20} ä¸ªå­—ç¬¦ä¸²")

    # æ˜¾ç¤ºæœ‰ä¸­æ–‡keyä½†è‹±æ–‡ç¿»è¯‘æœ‰é—®é¢˜çš„
    if has_zh_key_but_no_en:
        report.append("\n" + "=" * 80)
        report.append("âš ï¸ æœ‰ä¸­æ–‡keyä½†è‹±æ–‡ç¿»è¯‘ç¼ºå¤±æˆ–ä»ä¸ºä¸­æ–‡")
        report.append("=" * 80)
        report.append("")
        for item in has_zh_key_but_no_en[:30]:  # åªæ˜¾ç¤ºå‰30ä¸ª
            report.append(f"  Key: {item['key']}")
            report.append(f"  ä¸­æ–‡: {item['text']}")
            report.append(f"  è‹±æ–‡: {item['en_value'] or '(ç¼ºå¤±)'}")
            report.append(f"  ä½ç½®: è¡Œ {', '.join(map(str, item['lines'][:3]))}")
            report.append("")
        if len(has_zh_key_but_no_en) > 30:
            report.append(f"  ... è¿˜æœ‰ {len(has_zh_key_but_no_en)-30} é¡¹")

    # ä¿å­˜åˆ°æ–‡ä»¶
    report_text = '\n'.join(report)
    output_file = Path('config_gui_translation_analysis.txt')
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report_text)

    print(f"Report saved to: {output_file}")

    # ç”ŸæˆJSONæ ¼å¼çš„è¯¦ç»†æ•°æ®
    json_report = {
        'summary': {
            'total_chinese_strings': len(chinese_strings),
            'completely_missing': len(completely_missing),
            'has_key_but_no_en': len(has_zh_key_but_no_en)
        },
        'categorized_missing': categorized_missing,
        'has_key_but_no_en': has_zh_key_but_no_en,
        'all_missing': completely_missing
    }

    json_output_file = Path('config_gui_translation_analysis.json')
    with open(json_output_file, 'w', encoding='utf-8') as f:
        json.dump(json_report, f, ensure_ascii=False, indent=2)

    print(f"JSON data saved to: {json_output_file}")

if __name__ == '__main__':
    main()
